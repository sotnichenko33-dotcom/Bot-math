., [26.02.2026 15:03]
import os
import logging
import base64
import io

import matplotlib.pyplot as plt
import sympy as sp
import numpy as np

from aiogram import Bot, Dispatcher, executor, types
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from openai import OpenAI
from duckduckgo_search import DDGS

# ================== –ù–ê–°–¢–†–û–ô–ö–ò ==================

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not BOT_TOKEN or not OPENAI_API_KEY:
    raise RuntimeError("‚ùå BOT_TOKEN –∏–ª–∏ OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω—ã")

logging.basicConfig(level=logging.INFO)

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(bot)
client = OpenAI(api_key=OPENAI_API_KEY)

# ================== –ü–ê–ú–Ø–¢–¨ ==================

user_memory = {}
user_mode = {}
MAX_MEMORY = 6

# ================== –ö–ù–û–ü–ö–ò ==================

keyboard = ReplyKeyboardMarkup(resize_keyboard=True)
keyboard.add(
    KeyboardButton("üìñ –†–µ—à–∏—Ç—å –ø–æ —à–∞–≥–∞–º"),
    KeyboardButton("‚ö° –ö—Ä–∞—Ç–∫–æ")
)
keyboard.add(
    KeyboardButton("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–ª–æ–≥")
)

# ================== –ò–ù–¢–ï–†–ù–ï–¢ ==================

def web_search(query: str) -> str:
    with DDGS() as ddgs:
        results = [
            f"- {r['title']}: {r['body']}"
            for r in ddgs.text(query, max_results=3)
        ]
    return "\n".join(results)

# ================== –ì–†–ê–§–ò–ö ==================

def looks_like_graph_request(text: str) -> bool:
    triggers = ["y =", "f(x)", "–≥—Ä–∞—Ñ–∏–∫", "–ø–æ—Å—Ç—Ä–æ–π", "–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å"]
    text = text.lower()
    return any(t in text for t in triggers)

def build_graph(expr_text: str):
    x = sp.symbols("x")
    expr_text = expr_text.replace("^", "**")

    if "=" in expr_text:
        expr_text = expr_text.split("=")[1]

    expr = sp.sympify(expr_text)
    func = sp.lambdify(x, expr, "numpy")

    xs = np.linspace(-10, 10, 400)
    ys = func(xs)

    plt.figure()
    plt.plot(xs, ys)
    plt.axhline(0)
    plt.axvline(0)
    plt.grid()

    buf = io.BytesIO()
    plt.savefig(buf, format="png")
    plt.close()
    buf.seek(0)
    return buf

# ================== –ò–ò (–¢–ï–ö–°–¢) ==================

def ai_answer(user_id: int, text: str) -> str:
    mode = user_mode.get(user_id, "steps")
    web_info = web_search(text)
    memory = user_memory.get(user_id, [])

    system = "–¢—ã —É–º–Ω—ã–π –ò–ò-—Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä."
    if mode == "steps":
        system += " –†–µ—à–∞–π –ü–û –®–ê–ì–ê–ú."
    else:
        system += " –û—Ç–≤–µ—á–∞–π –ö–†–ê–¢–ö–û."

    messages = [{"role": "system", "content": system}]
    messages += memory
    messages.append({
        "role": "user",
        "content": f"–ò–Ω—Ç–µ—Ä–Ω–µ—Ç:\n{web_info}\n\n–í–æ–ø—Ä–æ—Å:\n{text}"
    })

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.3
    )

    answer = resp.choices[0].message.content.strip()

    memory.append({"role": "user", "content": text})
    memory.append({"role": "assistant", "content": answer})
    user_memory[user_id] = memory[-MAX_MEMORY:]

    return answer

# ================== HANDLERS ==================

@dp.message_handler(commands=["start"])
async def start(message: types.Message):
    user_mode[message.from_user.id] = "steps"
    user_memory[message.from_user.id] = []
    await message.answer(
        "üëã –Ø –ò–ò-—Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ üìä\n\n"
        "–Ø —É–º–µ—é:\n"
        "‚Ä¢ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏\n"
        "‚Ä¢ —Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏\n"
        "‚Ä¢ –æ–±—ä—è—Å–Ω—è—Ç—å –ø–æ —à–∞–≥–∞–º\n"
        "‚Ä¢ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ñ–æ—Ç–æ\n\n"
        "–ù–∞–ø–∏—à–∏ –∑–∞–¥–∞—á—É üëá",
        reply_markup=keyboard
    )

@dp.message_handler(lambda m: m.text == "üìñ –†–µ—à–∏—Ç—å –ø–æ —à–∞–≥–∞–º")
async def mode_steps(message: types.Message):
    user_mode[message.from_user.id] = "steps"
    await message.answer("üìñ –†–µ–∂–∏–º: –ø–æ —à–∞–≥–∞–º")

@dp.message_handler(lambda m: m.text == "‚ö° –ö—Ä–∞—Ç–∫–æ")
async def mode_short(message: types.Message):
    user_mode[message.from_user.id] = "short"
    await message.answer("‚ö° –†–µ–∂–∏–º: –∫—Ä–∞—Ç–∫–æ")

@dp.message_handler(lambda m: m.text == "üîÑ –°–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–ª–æ–≥")
async def reset(message: types.Message):
    user_memory[message.from_user.id] = []
    await message.answer("üîÑ –î–∏–∞–ª–æ–≥ –æ—á–∏—â–µ–Ω")

@dp.message_handler(content_types=types.ContentType.TEXT)

., [26.02.2026 15:03]
async def handle_text(message: types.Message):
    text = message.text

    if looks_like_graph_request(text):
        try:
            graph = build_graph(text)
            await message.answer_photo(
                photo=graph,
                caption="üìä –ì—Ä–∞—Ñ–∏–∫ —Ñ—É–Ω–∫—Ü–∏–∏"
            )
        except Exception:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫")

    await message.answer("üß† –î—É–º–∞—é...")
    answer = ai_answer(message.from_user.id, text)
    await message.answer(answer)

# ================== START ==================

if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)